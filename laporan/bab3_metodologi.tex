% =================================================================
% BAB 3: METODOLOGI PENELITIAN (VERSI FIX & RIGID)
% =================================================================

\section{Metodologi Penelitian}
\label{sec:metodologi}

Penelitian ini menggunakan pendekatan eksperimental kuantitatif. Rangkaian pengujian dirancang untuk mengukur kinerja kriptografis dengan mengontrol variabel sistem, sehingga membatasi interferensi eksternal dan memungkinkan reproduksibilitas pengujian (\textit{reproducible}).

\subsection{Konfigurasi Lingkungan Pengujian}
Untuk meminimalisir bias dari \textit{overhead} sistem operasi, spesifikasi perangkat keras dan tumpukan perangkat lunak (\textit{software stack}) dibakukan pada konfigurasi berikut:
\begin{itemize}
	\item \textbf{Prosesor (CPU):} 12th Gen Intel(R) Core(TM) i5-12450H (Arsitektur Alder Lake, 8 \textit{Physical Cores}, 12 \textit{Threads}).
	\item \textbf{Memori (RAM):} 16.0 GB DDR4.
	\item \textbf{Sistem Operasi:} Windows 11 64-bit (Build 10.0.26200).
	\item \textbf{Lingkungan Eksekusi:} Python versi 3.14.2 menggunakan pustaka \texttt{hashlib} standar sebagai \textit{wrapper} untuk \textit{library} OpenSSL. Untuk membuktikan validitas eksperimental kausalitas perangkat keras, eksekusi dipisah menjadi dua jalur kontrol (\textit{Control Groups}):
    \begin{itemize}
        \item \textbf{Hardware-Accelerated (Default):} Membiarkan abstraksi sistem operasi memanggil utilitas \textit{Intel Secure Hash Algorithm Extensions} (SHA-NI).
        \item \textbf{Software-Only (Isolated):} Memaksa modul OpenSSL memintas instruksi kriptografi presisi dengan menanamkan variabel \textit{environment} OS \verb|OPENSSL_ia32cap="~0x20000000"| pada saat \textit{runtime}.
    \end{itemize}
\end{itemize}

\subsection{Persiapan Dataset Uji}
Dataset pengujian tidak menggunakan file teks standar, melainkan \textit{pseudo-random byte sequence} yang diekstraksi dari fungsi \texttt{os.urandom} OS. Data dipra-generasi ke dalam \textit{in-memory payload} (RAM) sebelum fase benchmarking dijalankan, demi menghindari \textit{bottleneck disk-I/O Storage}. Varian ukuran data yang diuji adalah 1 MB, 10 MB, 100 MB, dan 1 GB.

\subsection{Skenario dan Tahapan Pengujian}
Protokol pengujian mengadopsi standar \textit{benchmarking} dari Raj Jain \cite{jain1991} yang diilustrasikan pada diagram alir di Gambar \ref{fig:flowchart}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{grafik_output/flowchart.png}
	\caption{Diagram Alir (Flowchart) Skenario Pengujian Algoritma Hash}
	\label{fig:flowchart}
\end{figure}

Tahapan pengujian dilakukan secara sekuensial untuk setiap algoritma:
\begin{enumerate}
	\item \textbf{\textit{Warm-up Phase}:} Setiap algoritma mengeksekusi hash sebanyak 2 kali tanpa dilakukan pencatatan hasil. Fase heuristik ini bertujuan untuk menginisialisasi tabel rotasi di dalam \textit{cache L1/L2 silikon CPU} sebelum pencatatan \texttt{perf\_counter\_ns} dimulai. Walaupun eksperimen tidak memverifikasi secara matematis pencapaian \textit{steady-state} dalam 2 iterasi, langkah ini secara observasional cukup mereduksi \textit{cold-start bias} awal iterasi CPython.
	\item \textbf{\textit{Evaluation Phase}:} Setiap kombinasi algoritma dan ukuran file diuji sebanyak 30 iterasi independen (dengan payload acak baru pada tiap putaran). Harus diakui bahwa eksperimen repetitif pada mesin yang sama memiliki potensi autokorelasi temporal (seperti \textit{thermal throttling}), namun pengacakan \textit{payload} diharapkan menyerap variabilitas tersebut.
\end{enumerate}

\subsection{Logika Implementasi Benchmark}
Kalkulasi kecepatan (\textit{throughput}) menggunakan \texttt{time.perf\_counter\_ns()}. Fungsi ini mengakses \textit{hardware monotonic clock} pada prosesor, yang meminimalisir deviasi latensi waktu pembacaan dibandingkan fungsi pencatat waktu standar tingkat OS (\textit{wall-clock}). Selanjutnya, konsumsi sumber daya CPU diukur secara terisolasi menggunakan metode \texttt{psutil.Process().cpu\_times()}, bukan melaui persentase utilisasi sistem global. Parameter ini merekam waktu eksekusi \textit{User Time} (kalkulasi instruksi aplikasi) dan \textit{System Time} (waktu \textit{OS routine}), yang bertujuan untuk merekam beban CPU aplikasi secara independen guna memitigasi distorsi dari proses berlatar OS (\textit{system interrupts}). Kendati \textit{jitter} dari pergeseran \textit{scheduler} OS pada tingkat milidetik tetap berpotensi terjadi, skala korpus data pengujian yang besar diharapkan mereduksi signifikansi \textit{noise} tersebut.

\subsection{Evaluasi Properti Difusi (Strict Avalanche Criterion)}
Pengujian dilakukan untuk mengukur kualitas penyebaran bit pada keluaran hash berbasis \textit{Strict Avalanche Criterion} \cite{webster1986}. Metrik probabilitas di pengujian Avalanche ini difokuskan secara independen pada kualitas difusi. Evaluasi SAC memproyeksikan stabilitas pengacakan data semata, dan bukan representasi ukur matematis langsung bagi ketahanan kolisi (\textit{collision resistance}) ataupun ketahanan prabayangan (\textit{preimage resistance}).

Dalam pengujian skala besar, $N=10.000$ blok masukan acak mandiri berkapasitas 64-byte di-induksasikan skema pembalikan (\textit{bit flipping}) tepat pada satu unit acak bit tunggal secara beraturan silang (\textit{uniform independent bit inverison}). Perbedaan selisih di antara \textit{hash digest} awal dan inversi diekstraksi ke observasi jarak diskrit berupa \textit{Hamming Distance}. Perlu ditekankan bahwa observasi ini merupakan evaluasi makroskopik berbasis rata-rata global, dan tidak diformulasikan untuk menguji korelasi antar bit tunggal (\textit{strict bit-independence}) yang berada di ranah analisis kriptoanalisis mendalam. Validasi kecukupan sebaran bit diekstrak menggunakan Uji Keselarasan (\textit{Chi-Square Goodness-of-Fit Test}), dikomparasikan pada referensi kurva deviasi teoretik dasar \textit{Binomial Distribution} $B(256, 0.5)$ (kelas sebaran variabel acak pada ekor kurva dengan frekuensi ekspektasi $<5$ diagregasi untuk mensintesis $df=25$ kelas *bin* valid sesuai asumsi standar pengujian minimum Pearson).

\subsection{Rancangan Analisis Statistik}
Analisis komparatif menggunakan model \textit{Two-Way Factorial Analysis of Variance} (ANOVA). Rancangan eksperimen faktorial ini menggunakan dua parameter utama: Jenis Algoritma (3 level: SHA-256, SHA-3, BLAKE2) dan Ukuran File Dataset (4 level: 1MB, 10MB, 100MB, 1GB). Pengamatan didapatkan melalui 30 iterasi pengujian per kombinasi perlakuan, menghasilkan total observasi $N=360$ di luar proses pengabaian \textit{warm-up}. 

Model ANOVA berfokus mengevaluasi signifikansi efek (\textit{Interaction Term: Algoritma $\times$ Ukuran File}) terhadap metrik \textit{throughput}. Validasi inferensi statistik diasumsikan mematuhi postulat asimptotik Teorema Limit Pusat (\textit{Central Limit Theorem}) untuk normalitas residual mengingat kecukupan ruang sampel per-sel (\textit{n=30}). Homogenitas varians diestimasi proporsional melalui kontrol observasi sampel setara (\textit{balanced design}), sekalipun pengujian prasyarat formal (seperti \textit{Levene's Test}) dan uji tren sekuensial deret waktu tidak disertakan secara definitif dalam laporan ini untuk resolusi 1 GB. Ukuran magnitud pengaruh dilaporkan menggunakan model observasional \textit{Effect Size partial eta-squared} ($\eta^2_p$). Perbedaan rata-rata kelompok diuji komparasinya melalui metode \textit{post-hoc Bonferroni pairwise confidence interval} sebesar 95\%.